{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from src.method_selector import MlMethodSelector, ClassicMethodSelector\n",
    "from src.measurement_provider import MeasurementProvider\n",
    "from src.serializer import SenMLCBORSerializer, SenMLJSONSerializer\n",
    "from src.signal_generator import SignalGenerator\n",
    "from sys import getsizeof\n",
    "from src.metric import FeatureMetricEnum, SimilarityMetricEnum\n",
    "from src.data_type import Measurement\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from src.metric import SimilarityMetricEnum\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sizes(dataset, compressed_data, metrics):\n",
    "  senML_cbor_size_original = getsizeof(SenMLCBORSerializer.serialize(dataset, '/72/', '1/2', metrics))\n",
    "  senML_cbor_size_compressed = getsizeof(SenMLCBORSerializer.serialize(compressed_data, '/72/', '1/2', metrics))\n",
    "  senML_cbor_size_diff = senML_cbor_size_original - senML_cbor_size_compressed\n",
    "  senML_cbor_size_ratio = senML_cbor_size_diff / senML_cbor_size_original\n",
    "  # print(senML_cbor_size_original, senML_cbor_size_compressed, senML_cbor_size_diff, senML_cbor_size_ratio)\n",
    "\n",
    "  senML_json_size_original = getsizeof(SenMLJSONSerializer.serialize(dataset, '/72/', '1/2', metrics))\n",
    "  senML_json_size_compressed = getsizeof(SenMLJSONSerializer.serialize(compressed_data, '/72/', '1/2', metrics))\n",
    "  senML_json_size_diff = senML_json_size_original - senML_json_size_compressed\n",
    "  senML_json_size_ratio = senML_json_size_diff / senML_json_size_original\n",
    "  # print(senML_json_size_original, senML_json_size_compressed, senML_json_size_diff, senML_json_size_ratio)\n",
    "  return {\n",
    "    'senML_cbor_size_original': senML_cbor_size_original,\n",
    "    'senML_cbor_size_compressed': senML_cbor_size_compressed,\n",
    "    'senML_cbor_size_diff': senML_cbor_size_diff,\n",
    "    'senML_cbor_size_ratio': senML_cbor_size_ratio,\n",
    "\n",
    "    'senML_json_size_original': senML_json_size_original,\n",
    "    'senML_json_size_compressed': senML_json_size_compressed,\n",
    "    'senML_json_size_diff': senML_json_size_diff,\n",
    "    'senML_json_size_ratio': senML_json_size_ratio,\n",
    "  }\n",
    "\n",
    "def current_milis():\n",
    "  return time.time() * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_provider = MeasurementProvider()\n",
    "dataset1 = measurement_provider.get_random3()\n",
    "dataset2 = [measurement_provider.json_to_measurements('stock1.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_method_selector = MlMethodSelector()\n",
    "# ml_method_selector.use_default_strategy([\n",
    "#   SimilarityMetricEnum.arithmetic_average,\n",
    "#   SimilarityMetricEnum.median,\n",
    "#   SimilarityMetricEnum.covariance,\n",
    "# ])\n",
    "ml_method_selector.set_measurements(dataset1)\n",
    "score = ml_method_selector.train()\n",
    "print(score)\n",
    "\n",
    "classic_method_selector = ClassicMethodSelector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"datasize,ml_time,classic_time,ml_compressed_size,classic_compressed_size,ml_compression_ratio,classic_compression_ratio,ml_method,classic_method,ml_score,classic_score,ml_cbor_original_size,ml_cbor_compressed_size,ml_cbor_compressratio,classic_cbor_original_size,classic_cbor_compressed_size,classic_cbor_compressratio,ml_json_original_size,ml_json_compressed_size,ml_json_compressratio,classic_json_original_size,classic_json_compressed_size,classic_json_compressratio\")\n",
    "\n",
    "results = {\n",
    "  \"datasize\": [],\n",
    "  \"ml_time\": [],\n",
    "  \"classic_time\": [],\n",
    "  \"ml_compressed_size\": [],\n",
    "  \"classic_compressed_size\": [],\n",
    "  \"ml_compression_ratio\": [],\n",
    "  \"classic_compression_ratio\": [],\n",
    "  \"ml_method\": [],\n",
    "  \"classic_method\": [],\n",
    "  \"ml_score\": [],\n",
    "  \"classic_score\": [],\n",
    "  \"ml_cbor_original_size\": [],\n",
    "  \"ml_cbor_compressed_size\": [],\n",
    "  \"ml_cbor_compressratio\": [],\n",
    "  \"classic_cbor_original_size\": [],\n",
    "  \"classic_cbor_compressed_size\": [],\n",
    "  \"classic_cbor_compressratio\": [],\n",
    "  \"ml_json_original_size\": [],\n",
    "  \"ml_json_compressed_size\": [],\n",
    "  \"ml_json_compressratio\": [],\n",
    "  \"classic_json_original_size\": [],\n",
    "  \"classic_json_compressed_size\": [],\n",
    "  \"classic_json_compressratio\": [],\n",
    "}\n",
    "\n",
    "for datasize in [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]:\n",
    "  # measurements = measurement_provider.to_measurements(SignalGenerator(0, datasize).with_peaks(3).with_peaks(3, direction=-1).sin(0.2, 0.2))\n",
    "  measurements = measurement_provider.to_measurements(SignalGenerator(0, datasize).linear(2).sin(0.2, 0.2))\n",
    "\n",
    "  time_start = current_milis()\n",
    "  compressed_data, stats, metrics = ml_method_selector.compress_with_best(measurements)\n",
    "  time_end = current_milis()\n",
    "  serialized_data_stats = compute_sizes(measurements, compressed_data, metrics)\n",
    "  metrics_score = ClassicMethodSelector().compute_similarity_with_default_strategy(measurements, compressed_data)\n",
    "\n",
    "  ml_time = time_end - time_start\n",
    "  ml_compressed_size = stats['compressed_size']\n",
    "  ml_compression_ratio = stats['compression_rate']\n",
    "  ml_method = stats['method_name']\n",
    "  ml_score = metrics_score\n",
    "  ml_cbor_original_size = serialized_data_stats['senML_cbor_size_original']\n",
    "  ml_cbor_compressed_size = serialized_data_stats['senML_cbor_size_compressed']\n",
    "  ml_cbor_compressratio = serialized_data_stats['senML_cbor_size_ratio']\n",
    "  ml_json_original_size = serialized_data_stats['senML_json_size_original']\n",
    "  ml_json_compressed_size = serialized_data_stats['senML_json_size_compressed']\n",
    "  ml_json_compressratio = serialized_data_stats['senML_json_size_ratio']\n",
    "\n",
    "  results['datasize'].append(datasize);\n",
    "  results['ml_time'].append(ml_time);\n",
    "  results['ml_compressed_size'].append(ml_compressed_size);\n",
    "  results['ml_compression_ratio'].append(ml_compression_ratio);\n",
    "  results['ml_method'].append(ml_method);\n",
    "  results['ml_score'].append(ml_score);\n",
    "  results['ml_cbor_original_size'].append(ml_cbor_original_size);\n",
    "  results['ml_cbor_compressed_size'].append(ml_cbor_compressed_size);\n",
    "  results['ml_cbor_compressratio'].append(ml_cbor_compressratio);\n",
    "  results['ml_json_original_size'].append(ml_json_original_size);\n",
    "  results['ml_json_compressed_size'].append(ml_json_compressed_size);\n",
    "  results['ml_json_compressratio'].append(ml_json_compressratio);\n",
    "\n",
    "  ##############################################\n",
    "\n",
    "  time_start = current_milis()\n",
    "  compressed_data, stats, metrics, metrics_score = classic_method_selector.compress_with_best_default_strategy(measurements)\n",
    "  time_end = current_milis()\n",
    "  serialized_data_stats = compute_sizes(measurements, compressed_data, metrics)\n",
    "\n",
    "  classic_time = time_end - time_start\n",
    "  classic_compressed_size = stats['compressed_size']\n",
    "  classic_compression_ratio = stats['compression_rate']\n",
    "  classic_method = stats['method_name']\n",
    "  classic_score = metrics_score\n",
    "  classic_cbor_original_size = serialized_data_stats['senML_cbor_size_original']\n",
    "  classic_cbor_compressed_size = serialized_data_stats['senML_cbor_size_compressed']\n",
    "  classic_cbor_compressratio = serialized_data_stats['senML_cbor_size_ratio']\n",
    "  classic_json_original_size = serialized_data_stats['senML_json_size_original']\n",
    "  classic_json_compressed_size = serialized_data_stats['senML_json_size_compressed']\n",
    "  classic_json_compressratio = serialized_data_stats['senML_json_size_ratio']\n",
    "\n",
    "  results['classic_time'].append(classic_time);\n",
    "  results['classic_compressed_size'].append(classic_compressed_size);\n",
    "  results['classic_compression_ratio'].append(classic_compression_ratio);\n",
    "  results['classic_method'].append(classic_method);\n",
    "  results['classic_score'].append(classic_score);\n",
    "  results['classic_cbor_original_size'].append(classic_cbor_original_size);\n",
    "  results['classic_cbor_compressed_size'].append(classic_cbor_compressed_size);\n",
    "  results['classic_cbor_compressratio'].append(classic_cbor_compressratio);\n",
    "  results['classic_json_original_size'].append(classic_json_original_size);\n",
    "  results['classic_json_compressed_size'].append(classic_json_compressed_size);\n",
    "  results['classic_json_compressratio'].append(classic_json_compressratio);\n",
    "\n",
    "  print(f'{datasize},{ml_time},{classic_time},{ml_compressed_size},{classic_compressed_size},{ml_compression_ratio},{classic_compression_ratio},{ml_method},{classic_method},{ml_score},{classic_score},{ml_cbor_original_size},{ml_cbor_compressed_size},{ml_cbor_compressratio},{classic_cbor_original_size},{classic_cbor_compressed_size},{classic_cbor_compressratio},{ml_json_original_size},{ml_json_compressed_size},{ml_json_compressratio},{classic_json_original_size},{classic_json_compressed_size},{classic_json_compressratio}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='datasize', y=['ml_time', 'classic_time'], grid=True)\n",
    "df.plot(x='datasize', y=['ml_compression_ratio', 'classic_compression_ratio'], grid=True, ylim=0)\n",
    "df.plot(x='datasize', y=['ml_compressed_size', 'classic_compressed_size'], grid=True, ylim=0)\n",
    "df.plot(x='datasize', y=['ml_score', 'classic_score'], grid=True, ylim=(0, 18))\n",
    "df.plot(x='datasize', y=['ml_cbor_compressed_size', 'classic_cbor_compressed_size', 'ml_json_compressed_size', 'classic_json_compressed_size'], grid=True, ylim=0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "617200769ce879efa1ebdc3ebfdf1b30a3a751f12c1f5537e4552fa514699a70"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
